{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2407,
     "status": "ok",
     "timestamp": 1686033869423,
     "user": {
      "displayName": "Joan Pascual",
      "userId": "10912815706478162654"
     },
     "user_tz": -120
    },
    "id": "jP765V8b7Q16",
    "outputId": "f1638980-71c2-4e68-f1cc-ba413ed03610"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "filename = \"/content/drive/Shareddrives/UPC-video-caption/01-DATASET/train/captions.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "H3mOTld3Nx8l"
   },
   "source": [
    "**CSV Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1882,
     "status": "ok",
     "timestamp": 1685473687379,
     "user": {
      "displayName": "Sergi Taramon Garcia",
      "userId": "15223757172759515165"
     },
     "user_tz": -120
    },
    "id": "h6xaXeWE51_q",
    "outputId": "34aaccdd-f977-4929-ebf5-12ebd6178c40"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Read CSV file\n",
    "with open(filename, newline=\"\") as csvfile:\n",
    "    reader = list(csv.reader(csvfile, delimiter=\" \", quotechar=\"|\"))\n",
    "\n",
    "    # Process rows and create token dictionary\n",
    "    token_dictionary = []\n",
    "    for row in reader:\n",
    "        last_element = row[-1].split(\",\")[0]\n",
    "        clean_row = row[:-1] + [last_element]\n",
    "        token_dictionary.extend(clean_row)\n",
    "\n",
    "# Create sorted token dictionary\n",
    "unique_token_dictionary = sorted(set(token_dictionary))\n",
    "\n",
    "print(token_dictionary)\n",
    "print(len(token_dictionary))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Zkcx6wtrN6dj"
   },
   "source": [
    "**Pandad Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3964,
     "status": "ok",
     "timestamp": 1686033881410,
     "user": {
      "displayName": "Joan Pascual",
      "userId": "10912815706478162654"
     },
     "user_tz": -120
    },
    "id": "nQBdtH6L-oyH",
    "outputId": "5a6087c6-e631-4788-d31c-ff61e332afa8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Splitting all caption cells into tokens\n",
    "token_dictionary = np.concatenate(df.iloc[:, 0].str.split().values)\n",
    "\n",
    "unique_token_dictionary = set(token_dictionary)\n",
    "print(\"token_dictionary lenght: \")\n",
    "print(len(token_dictionary))\n",
    "print(\"unique_token_dictionary lenght:\")\n",
    "print(len(unique_token_dictionary))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "i7o5osfYoZrl"
   },
   "source": [
    "**List of words ordered by frecuency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1686033887574,
     "user": {
      "displayName": "Joan Pascual",
      "userId": "10912815706478162654"
     },
     "user_tz": -120
    },
    "id": "se5204pO-ldx",
    "outputId": "dca06992-3392-4d11-abe7-2dd25b06256b"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "words_frequencies = collections.Counter(token_dictionary)\n",
    "words_frequencies = sorted(words_frequencies, key=lambda x: words_frequencies[x], reverse=True)\n",
    "\n",
    "words_frequencies.insert(0, \"<eos>\")\n",
    "words_frequencies.insert(0, \"<sos>\")\n",
    "words_frequencies.insert(0, \"<unk>\")\n",
    "words_frequencies.insert(0, \"<pad>\")\n",
    "\n",
    "print(\"words_frequencies lenght:\", len(words_frequencies))\n",
    "\n",
    "truncated_words_frequencies = words_frequencies[:10000]\n",
    "\n",
    "print(\"truncated_words_frequencies lenght:\", len(truncated_words_frequencies))\n",
    "print(truncated_words_frequencies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gTnNQF5Ro5F4"
   },
   "source": [
    "**Order sentences by length keeping videoId**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1686033900129,
     "user": {
      "displayName": "Joan Pascual",
      "userId": "10912815706478162654"
     },
     "user_tz": -120
    },
    "id": "JZm4LGK2pFsL",
    "outputId": "49788ea2-e4d3-40c7-8287-bdb7f8d646f3"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "sentences_dict = {}\n",
    "\n",
    "with open(filename, \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header row if present\n",
    "\n",
    "    for row in reader:\n",
    "        sentence = row[0]  # Sentence is in the first column\n",
    "        video_id = row[1]  # Video ID is in the second column\n",
    "\n",
    "        sentence_length = len(sentence)\n",
    "        sentences_dict[video_id] = sentence\n",
    "\n",
    "# Create a new dictionary by sorting the items based on sentence length\n",
    "sorted_sentences_dict = {\n",
    "    k: v for k, v in sorted(sentences_dict.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "}\n",
    "\n",
    "print(sorted_sentences_dict)\n",
    "# for key, value in sorted_dict.items():\n",
    "# print(key, value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PhqFf1FHOD3z"
   },
   "source": [
    "Encoder (https://buomsoo-kim.github.io/attention/2020/04/21/Attention-mechanism-19.md/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crWH_shXODM7"
   },
   "outputs": [],
   "source": [
    "class TransformerNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_src_vocab,\n",
    "        num_tgt_vocab,\n",
    "        embedding_dim,\n",
    "        hidden_size,\n",
    "        nheads,\n",
    "        n_layers,\n",
    "        max_src_len,\n",
    "        max_tgt_len,\n",
    "        dropout,\n",
    "    ):\n",
    "        super(TransformerNet, self).__init__()\n",
    "        # embedding layer\n",
    "        self.dec_embedding = nn.Embedding(len(unique_token_dictionary), embedding_dim)\n",
    "\n",
    "        # positional encoding layer\n",
    "        self.dec_pe = PositionalEncoding(embedding_dim, max_len=max_tgt_len)\n",
    "\n",
    "        # encoder/decoder layer\n",
    "        dec_layer = nn.TransformerDecoderLayer(embedding_dim, nheads, hidden_size, dropout)\n",
    "        self.decoder = nn.TransformerDecoder(dec_layer, num_layers=n_layers)\n",
    "\n",
    "        # final dense layer\n",
    "        self.dense = nn.Linear(embedding_dim, num_tgt_vocab)\n",
    "        self.log_softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        tgt = self.dec_embedding(tgt).permute(1, 0, 2)\n",
    "        tgt = self.dec_pe(tgt)\n",
    "        memory = self.encoder(src)\n",
    "        transformer_out = self.decoder(tgt, memory)\n",
    "        final_out = self.dense(transformer_out)\n",
    "        return self.log_softmax(final_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHb5PMWfO4qF"
   },
   "outputs": [],
   "source": [
    "## source: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
